{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import theano.tensor as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "print(all_teams[i])\n",
    "print(str(number_team[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_html(\"https://www.naqt.com/stats/tournament/standings.jsp?tournament_id=9500\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"data/03_primary/all_games.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all games\n",
    "all_games = io.load(\"2018_all_games\")\n",
    "rename_dict = {\n",
    "    \"P\":\"team_1_powers\",\n",
    "    \"TU\":\"team_1_tens\",\n",
    "    \"I\":\"team_1_negs\",\n",
    "    \"B\":\"team_1_bonus_points\",\n",
    "    \"PPB\":\"team_1_ppb\",\n",
    "    \"P.1\":\"team_2_powers\",\n",
    "    \"TU.1\":\"team_2_tens\",\n",
    "    \"I.1\":\"team_2_negs\",\n",
    "    \"B.1\":\"team_2_bonus_points\",\n",
    "    \"PPB.1\":\"team_2_ppb\",\n",
    "    \"team\":\"team_1\",\n",
    "    \"Opponent\":\"team_2\"\n",
    "}\n",
    "print(all_games.shape)\n",
    "all_games = (all_games\n",
    "             .rename(rename_dict, axis=1)\n",
    "             .query(\"Score != 'Forfeit'\")\n",
    "             .eval(\"team_1_score = team_1_powers * 15 + team_1_tens * 10 - team_1_negs * 5 + team_1_bonus_points\")\n",
    "             .eval(\"team_2_score = team_2_powers * 15 + team_2_tens * 10 - team_2_negs * 5 + team_2_bonus_points\")\n",
    "             .eval(\"point_diff = team_1_score - team_2_score\")\n",
    "             .drop([\"Result\"], axis=1)\n",
    "            )\n",
    "all_games[\"point_diff_normalized\"] = (all_games[\"point_diff\"] - all_games[\"point_diff\"].mean()) / all_games[\"point_diff\"].std()\n",
    "\n",
    "# Add a unique numeric index for each team\n",
    "team_indices = (pd.DataFrame(list(set(all_games[\"team_1\"].unique()) | set(all_games[\"team_2\"].unique())))\n",
    "                .reset_index()\n",
    "                .rename({0:\"team\"}, axis=1)\n",
    "                .set_index(\"team\")\n",
    "                .to_dict()[\"index\"]\n",
    "               )\n",
    "all_games[\"team_1_index\"] = all_games[\"team_1\"].map(team_indices)\n",
    "all_games[\"team_2_index\"] = all_games[\"team_2\"].map(team_indices)\n",
    "\n",
    "assert all_games[all_games[\"team_1_index\"].isna()].empty\n",
    "assert all_games[all_games[\"team_2_index\"].isna()].empty\n",
    "\n",
    "# Find and remove duplicate games\n",
    "all_games[\"teams\"] = [tuple(sorted(x)) for x in zip(all_games[\"team_1\"], all_games[\"team_2\"])]\n",
    "all_games = (all_games\n",
    "             .drop_duplicates([\"Round\", \"teams\"])\n",
    "             .drop([\"teams\"], axis=1)\n",
    "            )\n",
    "\n",
    "print(all_games.shape)\n",
    "all_games.columns = all_games.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_games.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Model and code are based on [this article](http://danielweitzenfeld.github.io/passtheroc/blog/2014/10/28/bayes-premier-league/).\n",
    "\n",
    "Our goal is to come up with an underlying team strength parameter as well as uncertainty around that team strength parameter. Let $y_{gj}$ be the observed score for team $j$ in game $g$. We model the score using a Poisson distribution i.e. $y_{gj}|\\theta_{gj} \\sim Poisson(\\theta_{gj})$. Note that there is one $\\theta_{gj}$ for each team in each round. \n",
    "\n",
    "At the next level of the model, we model each $\\theta$ as a log-linear function:\n",
    "$$\n",
    "\\log \\theta_{g1} = attack_1 - defense_2 \\\\\n",
    "\\log \\theta_{g2} = attack_2 - defense_1\n",
    "$$\n",
    "i.e. we assume there is an attack and defense strength for each team. These parameters are modeled as a hierarchical model where, for each team $t$,\n",
    "$$\n",
    "attack_t \\sim N(\\mu_{attack},\\tau_{attack}) \\\\\n",
    "defense_t \\sim N(\\mu_{defense},\\tau_{defense})\n",
    "$$\n",
    "And in turn we have hyperpriors where $\\mu_{attack}, \\mu_{defense} \\sim N(.,.)$ and $\\tau_{attack}, \\tau_{defense} \\sim Gamma(.,.)$\n",
    "\n",
    "To ensure identifiability, we make the attack and defense parameters sum to 0:\n",
    "$$\n",
    "\\sum_{t \\in Teams} attack_t = 0 \\\\\n",
    "\\sum_{t \\in Teams} defense_t = 0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_teams = len(set(all_games[\"team_1\"].unique()) | set(all_games[\"team_2\"].unique()))\n",
    "team_1 = all_games[\"team_1_index\"].values\n",
    "team_2 = all_games[\"team_2_index\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %debug\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    #hyperpriors\n",
    "    tau_attack = pm.Gamma('tau_attack', alpha=20, beta=20)\n",
    "    tau_defense = pm.Gamma('tau_defense', alpha=20, beta=20)\n",
    "#     intercept = pm.HalfNormal('intercept', sd=1)\n",
    "\n",
    "    # team-specific model parameters\n",
    "    atts_star = pm.Normal(\"atts_star\", mu=0, sd=tau_attack, shape=num_teams)\n",
    "    defs_star = pm.Normal(\"defs_star\", mu=0, sd=tau_defense, shape=num_teams)\n",
    "    \n",
    "    atts = pm.Deterministic('atts', atts_star - tt.mean(atts_star))\n",
    "    defs = pm.Deterministic('defs', defs_star - tt.mean(defs_star))\n",
    "    team_1_theta = tt.exp(atts[team_1] + defs[team_2])\n",
    "    team_2_theta = tt.exp(atts[team_2] + defs[team_1])\n",
    "    \n",
    "    # likelihood of observed data\n",
    "    team_1_points = pm.Poisson('team_1_points', mu=team_1_theta, observed=all_games[\"team_1_score\"])\n",
    "#     team_2_points = pm.Poisson('team_2_points', mu=team_2_theta, observed=all_games[\"team_2_score\"])\n",
    "\n",
    "    prior = pm.sample_prior_predictive(samples=1000)\n",
    "    trace = pm.sample()\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_ranks = (trace.get_values(\"atts\")).mean(axis=0).argsort()[::-1]\n",
    "team_indices_reverse = {val:key for key, val in team_indices.items()}\n",
    "[team_indices_reverse[idx] for idx in team_ranks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = az.from_pymc3(\n",
    "        trace=trace,\n",
    "        prior=prior,\n",
    "        posterior_predictive=posterior_predictive,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.check_test_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prior[\"team_1_points\"].mean(), prior[\"team_1_points\"].max())\n",
    "# print(prior[\"team_2_points\"].mean(), prior[\"team_2_points\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(prior[\"team_1_points\"].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %debug\n",
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "\n",
    "    #hyperpriors\n",
    "    sd_team_strength = pm.Gamma(\"sd_team_strength\", alpha=1, beta=1)\n",
    "    sd_likelihood = pm.Gamma(\"sd_likelihood\", alpha=1, beta=1)\n",
    "\n",
    "    # team-specific model parameters\n",
    "    team_strength = pm.Normal(\"team_strength\", mu=0, sd=sd_team_strength, shape=num_teams)\n",
    "    strengths = pm.Deterministic('strengths', team_strength - tt.mean(team_strength))\n",
    "\n",
    "    # likelihood of observed data\n",
    "    mu = strengths[team_1] - strengths[team_2]\n",
    "    point_diff = pm.Normal('point_diff', mu=mu, sd=sd_likelihood, observed=all_games[\"point_diff\"])\n",
    "    \n",
    "    prior = pm.sample_prior_predictive(samples=1000)\n",
    "    trace = pm.sample()\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from simulation_based_calibration import SBC, plot_sbc\n",
    "# sbc = SBC(my_model, \"y\",\n",
    "#         num_simulations=10)\n",
    "\n",
    "# sbc.run_simulations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior[\"point_diff\"].min(), prior[\"point_diff\"].mean(), prior[\"point_diff\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(prior[\"team_strength\"].flatten(), kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
